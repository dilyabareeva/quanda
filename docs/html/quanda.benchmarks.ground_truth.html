<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>quanda.benchmarks.ground_truth package &mdash; quanda 01.07.2024 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="_static/jquery.js?v=5d32c60e"></script>
        <script src="_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="_static/documentation_options.js?v=cea27b2f"></script>
        <script src="_static/doctools.js?v=9a2dae69"></script>
        <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" >
            
              <img src="_static/quanda_panda_black_bg.png" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="docs_api/modules.html">quanda</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">quanda</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">quanda.benchmarks.ground_truth package</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/quanda.benchmarks.ground_truth.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="quanda-benchmarks-ground-truth-package">
<h1>quanda.benchmarks.ground_truth package<a class="headerlink" href="#quanda-benchmarks-ground-truth-package" title="Link to this heading"></a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading"></a></h2>
</section>
<section id="module-quanda.benchmarks.ground_truth.linear_datamodeling">
<span id="quanda-benchmarks-ground-truth-linear-datamodeling-module"></span><h2>quanda.benchmarks.ground_truth.linear_datamodeling module<a class="headerlink" href="#module-quanda.benchmarks.ground_truth.linear_datamodeling" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">quanda.benchmarks.ground_truth.linear_datamodeling.</span></span><span class="sig-name descname"><span class="pre">LinearDatamodeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="docs_api/quanda.benchmarks.base.html#quanda.benchmarks.base.Benchmark" title="quanda.benchmarks.base.Benchmark"><code class="xref py py-class docutils literal notranslate"><span class="pre">Benchmark</span></code></a></p>
<p>Benchmark for the Linear Datamodeling Score metric.</p>
<p>The LDS measures how well a data attribution method can predict the effect of retraining
a model on different subsets of the training data. It computes the correlation between
the model’s output when retrained on subsets of the data and the attribution method’s predictions
of those outputs.</p>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><dl class="simple">
<dt>Sung Min Park, Kristian Georgiev, Andrew Ilyas, Guillaume Leclerc,</dt><dd><p>and Aleksander Mądry. (2023). “TRAK: attributing model behavior at scale”.
In Proceedings of the 40th International Conference on Machine Learning” (ICML’23), Vol. 202.
JMLR.org, Article 1128, (27074–27113).</p>
</dd>
</dl>
</li>
<li><p><a class="reference external" href="https://github.com/MadryLab/trak/">https://github.com/MadryLab/trak/</a></p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>checkpoint_paths</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.linear_datamodeling.html#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.assemble" title="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.assemble"><code class="xref py py-obj docutils literal notranslate"><span class="pre">assemble</span></code></a>(model, train_dataset, eval_dataset, ...)</p></td>
<td><p>Assembles the benchmark from existing components.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_eval_dataset</span></code>(dataset_str, eval_indices)</p></td>
<td><p>Downloads the HuggingFace evaluation dataset from given name.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.linear_datamodeling.html#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.download" title="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.download"><code class="xref py py-obj docutils literal notranslate"><span class="pre">download</span></code></a>(name, cache_dir, device, *args, ...)</p></td>
<td><p>This method loads precomputed benchmark components from a file and creates an instance from the state dictionary.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.linear_datamodeling.html#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.evaluate" title="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(explainer_cls[, expl_kwargs, ...])</p></td>
<td><p>Evaluate the given data attributor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.linear_datamodeling.html#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.generate" title="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a>(train_dataset, eval_dataset, model, ...)</p></td>
<td><p>This method generates the benchmark components and creates an instance.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">process_dataset</span></code>(dataset[, transform, ...])</p></td>
<td><p>Return the dataset using the given parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_devices</span></code>(model)</p></td>
<td><p>Infer device from model.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.__init__" title="Link to this definition"></a></dt>
<dd><p>Initializer for the <cite>LinearDatamodeling</cite> benchmark.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.alpha" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.assemble">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">assemble</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="docs_api/quanda.utils.training.trainer.html#quanda.utils.training.trainer.BaseTrainer" title="quanda.utils.training.trainer.BaseTrainer"><span class="pre">BaseTrainer</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer_fit_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correlation_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'kendall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'spearman'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'spearman'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_split</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'train'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.assemble"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.assemble" title="Link to this definition"></a></dt>
<dd><p>Assembles the benchmark from existing components.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.utils.data.Dataset</em><em>]</em>) – The training dataset used to train <cite>model</cite>. If a string is passed, it should be a HuggingFace dataset name.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model used to generate attributions.</p></li>
<li><p><strong>eval_dataset</strong> (<em>torch.utils.data.Dataset</em>) – The evaluation dataset to be used for the benchmark.</p></li>
<li><p><strong>dataset_split</strong> (<em>str</em><em>, </em><em>optional</em>) – The dataset split to use, by default “train”. Only used if <cite>train_dataset</cite> is a string.</p></li>
<li><p><strong>trainer</strong> (<em>Union</em><em>[</em><em>L.Trainer</em><em>, </em><a class="reference internal" href="docs_api/quanda.utils.training.html#quanda.utils.training.BaseTrainer" title="quanda.utils.training.BaseTrainer"><em>BaseTrainer</em></a><em>]</em>) – Trainer to be used for training the models on different subsets. Can be a Lightning Trainer or a <cite>BaseTrainer</cite>.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em>) – Directory to be used for caching. This directory will be used to save checkpoints of models
trained on different subsets of the training data.</p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – Identifier for the model, to be used in naming cached checkpoints.</p></li>
<li><p><strong>data_transform</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em><em>, </em><em>optional</em>) – Transform to be applied to the dataset, by default None.</p></li>
<li><p><strong>correlation_fn</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><em>CorrelationFnLiterals</em><em>]</em><em>, </em><em>optional</em>) – Correlation function to be used for the evaluation.</p></li>
<li><p><strong>m</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of subsets to be used for training the models, by default 100.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentage of datapoints to be used for training the models, by default 0.5.</p></li>
<li><p><strong>trainer_fit_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em><em>, </em><em>optional</em>) – Additional keyword arguments to be passed to the <cite>fit</cite> method of the trainer, by default None.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – Seed to be used for the evaluation, by default 42.</p></li>
<li><p><strong>use_predictions</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use model predictions or the true test labels for the evaluation, defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.bench_state">
<span class="sig-name descname"><span class="pre">bench_state</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.bench_state" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.cache_dir">
<span class="sig-name descname"><span class="pre">cache_dir</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.cache_dir" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.correlation_fn">
<span class="sig-name descname"><span class="pre">correlation_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">CorrelationFnLiterals</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.correlation_fn" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.dataset_str">
<span class="sig-name descname"><span class="pre">dataset_str</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.dataset_str" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.dataset_transform">
<span class="sig-name descname"><span class="pre">dataset_transform</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.dataset_transform" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.device">
<span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.device" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.download">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">download</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.download"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.download" title="Link to this definition"></a></dt>
<dd><p>This method loads precomputed benchmark components from a file and creates an instance from the state dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – Name of the benchmark to be loaded.</p></li>
<li><p><strong>eval_dataset</strong> (<em>torch.utils.data.Dataset</em>) – The evaluation dataset to be used for the benchmark.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.eval_dataset">
<span class="sig-name descname"><span class="pre">eval_dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.utils.data.Dataset</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.eval_dataset" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer_cls</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expl_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the given data attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer_cls</strong> (<em>type</em>) – Class of the explainer to be used for the evaluation.</p></li>
<li><p><strong>expl_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em><em>, </em><em>optional</em>) – Additional keyword arguments for the explainer, by default None.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Batch size to be used for the evaluation, defaults to 8</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary containing the evaluation results.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.generate">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="docs_api/quanda.utils.training.trainer.html#quanda.utils.training.trainer.BaseTrainer" title="quanda.utils.training.trainer.BaseTrainer"><span class="pre">BaseTrainer</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correlation_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'kendall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'spearman'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'spearman'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer_fit_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_split</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'train'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.generate" title="Link to this definition"></a></dt>
<dd><p>This method generates the benchmark components and creates an instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.utils.data.Dataset</em><em>]</em>) – The training dataset used to train <cite>model</cite>. If a string is passed, it should be a HuggingFace dataset name.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model used to generate attributions.</p></li>
<li><p><strong>eval_dataset</strong> (<em>torch.utils.data.Dataset</em>) – The evaluation dataset to be used for the benchmark.</p></li>
<li><p><strong>dataset_split</strong> (<em>str</em><em>, </em><em>optional</em>) – The dataset split to use, by default “train”. Only used if <cite>train_dataset</cite> is a string.</p></li>
<li><p><strong>trainer</strong> (<em>Union</em><em>[</em><em>L.Trainer</em><em>, </em><a class="reference internal" href="docs_api/quanda.utils.training.html#quanda.utils.training.BaseTrainer" title="quanda.utils.training.BaseTrainer"><em>BaseTrainer</em></a><em>]</em>) – Trainer to be used for training the models on different subsets. Can be a Lightning Trainer or a <cite>BaseTrainer</cite>.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em>) – Directory to be used for caching. This directory will be used to save checkpoints of models
trained on different subsets of the training data.</p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – Identifier for the model, to be used in naming cached checkpoints.</p></li>
<li><p><strong>data_transform</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em><em>, </em><em>optional</em>) – Transform to be applied to the dataset, by default None.</p></li>
<li><p><strong>correlation_fn</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><em>CorrelationFnLiterals</em><em>]</em><em>, </em><em>optional</em>) – Correlation function to be used for the evaluation.</p></li>
<li><p><strong>m</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of subsets to be used for training the models, by default 100.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentage of datapoints to be used for training the models, by default 0.5.</p></li>
<li><p><strong>trainer_fit_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em><em>, </em><em>optional</em>) – Additional keyword arguments to be passed to the <cite>fit</cite> method of the trainer, by default None.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – Seed to be used for the evaluation, by default 42.</p></li>
<li><p><strong>use_predictions</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use model predictions or the true test labels for the evaluation, defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.m">
<span class="sig-name descname"><span class="pre">m</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.m" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.model">
<span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.nn.Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">L.LightningModule</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.model_id">
<span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.model_id" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Linear</span> <span class="pre">Datamodeling</span> <span class="pre">Score'</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.name" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.seed">
<span class="sig-name descname"><span class="pre">seed</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.seed" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.train_dataset">
<span class="sig-name descname"><span class="pre">train_dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.utils.data.Dataset</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.train_dataset" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.trainer">
<span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">L.Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="docs_api/quanda.utils.training.html#quanda.utils.training.BaseTrainer" title="quanda.utils.training.BaseTrainer"><span class="pre">BaseTrainer</span></a></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.trainer" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.trainer_fit_kwargs">
<span class="sig-name descname"><span class="pre">trainer_fit_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.trainer_fit_kwargs" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.use_predictions">
<span class="sig-name descname"><span class="pre">use_predictions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.linear_datamodeling.LinearDatamodeling.use_predictions" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-quanda.benchmarks.ground_truth">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-quanda.benchmarks.ground_truth" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">quanda.benchmarks.ground_truth.</span></span><span class="sig-name descname"><span class="pre">LinearDatamodeling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="docs_api/quanda.benchmarks.base.html#quanda.benchmarks.base.Benchmark" title="quanda.benchmarks.base.Benchmark"><code class="xref py py-class docutils literal notranslate"><span class="pre">Benchmark</span></code></a></p>
<p>Benchmark for the Linear Datamodeling Score metric.</p>
<p>The LDS measures how well a data attribution method can predict the effect of retraining
a model on different subsets of the training data. It computes the correlation between
the model’s output when retrained on subsets of the data and the attribution method’s predictions
of those outputs.</p>
<p class="rubric">References</p>
<ol class="arabic simple">
<li><dl class="simple">
<dt>Sung Min Park, Kristian Georgiev, Andrew Ilyas, Guillaume Leclerc,</dt><dd><p>and Aleksander Mądry. (2023). “TRAK: attributing model behavior at scale”.
In Proceedings of the 40th International Conference on Machine Learning” (ICML’23), Vol. 202.
JMLR.org, Article 1128, (27074–27113).</p>
</dd>
</dl>
</li>
<li><p><a class="reference external" href="https://github.com/MadryLab/trak/">https://github.com/MadryLab/trak/</a></p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Attributes<span class="colon">:</span></dt>
<dd class="field-odd"><dl class="simple">
<dt><strong>checkpoint_paths</strong></dt><dd></dd>
</dl>
</dd>
</dl>
<p class="rubric">Methods</p>
<table class="autosummary longtable docutils align-default">
<tbody>
<tr class="row-odd"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.html#quanda.benchmarks.ground_truth.LinearDatamodeling.assemble" title="quanda.benchmarks.ground_truth.LinearDatamodeling.assemble"><code class="xref py py-obj docutils literal notranslate"><span class="pre">assemble</span></code></a>(model, train_dataset, eval_dataset, ...)</p></td>
<td><p>Assembles the benchmark from existing components.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">build_eval_dataset</span></code>(dataset_str, eval_indices)</p></td>
<td><p>Downloads the HuggingFace evaluation dataset from given name.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.html#quanda.benchmarks.ground_truth.LinearDatamodeling.download" title="quanda.benchmarks.ground_truth.LinearDatamodeling.download"><code class="xref py py-obj docutils literal notranslate"><span class="pre">download</span></code></a>(name, cache_dir, device, *args, ...)</p></td>
<td><p>This method loads precomputed benchmark components from a file and creates an instance from the state dictionary.</p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.html#quanda.benchmarks.ground_truth.LinearDatamodeling.evaluate" title="quanda.benchmarks.ground_truth.LinearDatamodeling.evaluate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">evaluate</span></code></a>(explainer_cls[, expl_kwargs, ...])</p></td>
<td><p>Evaluate the given data attributor.</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="docs_api/quanda.benchmarks.ground_truth.html#quanda.benchmarks.ground_truth.LinearDatamodeling.generate" title="quanda.benchmarks.ground_truth.LinearDatamodeling.generate"><code class="xref py py-obj docutils literal notranslate"><span class="pre">generate</span></code></a>(train_dataset, eval_dataset, model, ...)</p></td>
<td><p>This method generates the benchmark components and creates an instance.</p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">process_dataset</span></code>(dataset[, transform, ...])</p></td>
<td><p>Return the dataset using the given parameters.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-obj docutils literal notranslate"><span class="pre">set_devices</span></code>(model)</p></td>
<td><p>Infer device from model.</p></td>
</tr>
</tbody>
</table>
<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.__init__" title="Link to this definition"></a></dt>
<dd><p>Initializer for the <cite>LinearDatamodeling</cite> benchmark.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.alpha">
<span class="sig-name descname"><span class="pre">alpha</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">float</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.alpha" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.assemble">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">assemble</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="docs_api/quanda.utils.training.trainer.html#quanda.utils.training.trainer.BaseTrainer" title="quanda.utils.training.trainer.BaseTrainer"><span class="pre">BaseTrainer</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer_fit_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correlation_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'kendall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'spearman'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'spearman'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_split</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'train'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.assemble"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.assemble" title="Link to this definition"></a></dt>
<dd><p>Assembles the benchmark from existing components.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.utils.data.Dataset</em><em>]</em>) – The training dataset used to train <cite>model</cite>. If a string is passed, it should be a HuggingFace dataset name.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model used to generate attributions.</p></li>
<li><p><strong>eval_dataset</strong> (<em>torch.utils.data.Dataset</em>) – The evaluation dataset to be used for the benchmark.</p></li>
<li><p><strong>dataset_split</strong> (<em>str</em><em>, </em><em>optional</em>) – The dataset split to use, by default “train”. Only used if <cite>train_dataset</cite> is a string.</p></li>
<li><p><strong>trainer</strong> (<em>Union</em><em>[</em><em>L.Trainer</em><em>, </em><a class="reference internal" href="docs_api/quanda.utils.training.html#quanda.utils.training.BaseTrainer" title="quanda.utils.training.BaseTrainer"><em>BaseTrainer</em></a><em>]</em>) – Trainer to be used for training the models on different subsets. Can be a Lightning Trainer or a <cite>BaseTrainer</cite>.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em>) – Directory to be used for caching. This directory will be used to save checkpoints of models
trained on different subsets of the training data.</p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – Identifier for the model, to be used in naming cached checkpoints.</p></li>
<li><p><strong>data_transform</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em><em>, </em><em>optional</em>) – Transform to be applied to the dataset, by default None.</p></li>
<li><p><strong>correlation_fn</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><em>CorrelationFnLiterals</em><em>]</em><em>, </em><em>optional</em>) – Correlation function to be used for the evaluation.</p></li>
<li><p><strong>m</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of subsets to be used for training the models, by default 100.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentage of datapoints to be used for training the models, by default 0.5.</p></li>
<li><p><strong>trainer_fit_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em><em>, </em><em>optional</em>) – Additional keyword arguments to be passed to the <cite>fit</cite> method of the trainer, by default None.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – Seed to be used for the evaluation, by default 42.</p></li>
<li><p><strong>use_predictions</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use model predictions or the true test labels for the evaluation, defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.bench_state">
<span class="sig-name descname"><span class="pre">bench_state</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.bench_state" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.cache_dir">
<span class="sig-name descname"><span class="pre">cache_dir</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.cache_dir" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.correlation_fn">
<span class="sig-name descname"><span class="pre">correlation_fn</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">CorrelationFnLiterals</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.correlation_fn" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.dataset_str">
<span class="sig-name descname"><span class="pre">dataset_str</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.dataset_str" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.dataset_transform">
<span class="sig-name descname"><span class="pre">dataset_transform</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.dataset_transform" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.device">
<span class="sig-name descname"><span class="pre">device</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">torch.device</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.device" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.download">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">download</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.download"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.download" title="Link to this definition"></a></dt>
<dd><p>This method loads precomputed benchmark components from a file and creates an instance from the state dictionary.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – Name of the benchmark to be loaded.</p></li>
<li><p><strong>eval_dataset</strong> (<em>torch.utils.data.Dataset</em>) – The evaluation dataset to be used for the benchmark.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.eval_dataset">
<span class="sig-name descname"><span class="pre">eval_dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.utils.data.Dataset</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.eval_dataset" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">explainer_cls</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">expl_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">8</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.evaluate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluate the given data attributor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>explainer_cls</strong> (<em>type</em>) – Class of the explainer to be used for the evaluation.</p></li>
<li><p><strong>expl_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em><em>, </em><em>optional</em>) – Additional keyword arguments for the explainer, by default None.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – Batch size to be used for the evaluation, defaults to 8</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Dictionary containing the evaluation results.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.generate">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">generate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">eval_dataset</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Dataset</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="docs_api/quanda.utils.training.trainer.html#quanda.utils.training.trainer.BaseTrainer" title="quanda.utils.training.trainer.BaseTrainer"><span class="pre">BaseTrainer</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">cache_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_transform</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">correlation_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Callable</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">Literal</span><span class="p"><span class="pre">[</span></span><span class="s"><span class="pre">'kendall'</span></span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="s"><span class="pre">'spearman'</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'spearman'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">m</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">0.5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">trainer_fit_kwargs</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">42</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_predictions</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dataset_split</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">str</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'train'</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/quanda/benchmarks/ground_truth/linear_datamodeling.html#LinearDatamodeling.generate"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.generate" title="Link to this definition"></a></dt>
<dd><p>This method generates the benchmark components and creates an instance.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>train_dataset</strong> (<em>Union</em><em>[</em><em>str</em><em>, </em><em>torch.utils.data.Dataset</em><em>]</em>) – The training dataset used to train <cite>model</cite>. If a string is passed, it should be a HuggingFace dataset name.</p></li>
<li><p><strong>model</strong> (<em>torch.nn.Module</em>) – The model used to generate attributions.</p></li>
<li><p><strong>eval_dataset</strong> (<em>torch.utils.data.Dataset</em>) – The evaluation dataset to be used for the benchmark.</p></li>
<li><p><strong>dataset_split</strong> (<em>str</em><em>, </em><em>optional</em>) – The dataset split to use, by default “train”. Only used if <cite>train_dataset</cite> is a string.</p></li>
<li><p><strong>trainer</strong> (<em>Union</em><em>[</em><em>L.Trainer</em><em>, </em><a class="reference internal" href="docs_api/quanda.utils.training.html#quanda.utils.training.BaseTrainer" title="quanda.utils.training.BaseTrainer"><em>BaseTrainer</em></a><em>]</em>) – Trainer to be used for training the models on different subsets. Can be a Lightning Trainer or a <cite>BaseTrainer</cite>.</p></li>
<li><p><strong>cache_dir</strong> (<em>str</em>) – Directory to be used for caching. This directory will be used to save checkpoints of models
trained on different subsets of the training data.</p></li>
<li><p><strong>model_id</strong> (<em>str</em>) – Identifier for the model, to be used in naming cached checkpoints.</p></li>
<li><p><strong>data_transform</strong> (<em>Optional</em><em>[</em><em>Callable</em><em>]</em><em>, </em><em>optional</em>) – Transform to be applied to the dataset, by default None.</p></li>
<li><p><strong>correlation_fn</strong> (<em>Union</em><em>[</em><em>Callable</em><em>, </em><em>CorrelationFnLiterals</em><em>]</em><em>, </em><em>optional</em>) – Correlation function to be used for the evaluation.</p></li>
<li><p><strong>m</strong> (<em>int</em><em>, </em><em>optional</em>) – Number of subsets to be used for training the models, by default 100.</p></li>
<li><p><strong>alpha</strong> (<em>float</em><em>, </em><em>optional</em>) – Percentage of datapoints to be used for training the models, by default 0.5.</p></li>
<li><p><strong>trainer_fit_kwargs</strong> (<em>Optional</em><em>[</em><em>dict</em><em>]</em><em>, </em><em>optional</em>) – Additional keyword arguments to be passed to the <cite>fit</cite> method of the trainer, by default None.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – Seed to be used for the evaluation, by default 42.</p></li>
<li><p><strong>use_predictions</strong> (<em>bool</em><em>, </em><em>optional</em>) – Whether to use model predictions or the true test labels for the evaluation, defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.m">
<span class="sig-name descname"><span class="pre">m</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.m" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.model">
<span class="sig-name descname"><span class="pre">model</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.nn.Module</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">L.LightningModule</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.model" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.model_id">
<span class="sig-name descname"><span class="pre">model_id</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.model_id" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.name">
<span class="sig-name descname"><span class="pre">name</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'Linear</span> <span class="pre">Datamodeling</span> <span class="pre">Score'</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.name" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.seed">
<span class="sig-name descname"><span class="pre">seed</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">int</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.seed" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.train_dataset">
<span class="sig-name descname"><span class="pre">train_dataset</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">torch.utils.data.Dataset</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.train_dataset" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.trainer">
<span class="sig-name descname"><span class="pre">trainer</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">L.Trainer</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><a class="reference internal" href="docs_api/quanda.utils.training.html#quanda.utils.training.BaseTrainer" title="quanda.utils.training.BaseTrainer"><span class="pre">BaseTrainer</span></a></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.trainer" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.trainer_fit_kwargs">
<span class="sig-name descname"><span class="pre">trainer_fit_kwargs</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">dict</span><span class="w"> </span><span class="p"><span class="pre">|</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.trainer_fit_kwargs" title="Link to this definition"></a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="quanda.benchmarks.ground_truth.LinearDatamodeling.use_predictions">
<span class="sig-name descname"><span class="pre">use_predictions</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">bool</span></em><a class="headerlink" href="#quanda.benchmarks.ground_truth.LinearDatamodeling.use_predictions" title="Link to this definition"></a></dt>
<dd></dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Dilya, Galip.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>